# ğŸ¤– Chatbot em Cascata â€“ Projeto AcadÃªmico

## ğŸ“ DescriÃ§Ã£o
Este projeto implementa um chatbot em portuguÃªs baseado em arquitetura **em cascata**, onde dois modelos diferentes geram respostas a partir de um prompt do usuÃ¡rio, e um terceiro modelo atua como **Ã¡rbitro**, escolhendo a melhor resposta com base em critÃ©rios objetivos.

O web app foi desenvolvido utilizando **Gradio** e estÃ¡ hospedado no **Hugging Face Spaces**.

## ğŸš§ Funcionamento do Sistema

1. **UsuÃ¡rio insere uma pergunta (prompt).**
2. **Dois modelos geradores** processam o prompt e produzem **duas respostas independentes**.
3. **Um terceiro modelo (Ã¡rbitro)** analisa as duas respostas e seleciona a que melhor atende aos critÃ©rios definidos.
4. **A resposta escolhida Ã© exibida ao usuÃ¡rio**, juntamente com as duas respostas e a justificativa da escolha.

## âš™ï¸ Modelos Utilizados

### ğŸ“¤ Modelos Geradores

1. **pierreguillou/gpt2-small-portuguese**
   - Baseado no GPT-2, treinado especificamente em portuguÃªs.
   - Modelo leve (124M parÃ¢metros), ideal para ambientes com 2vCPU e 16GB RAM.
   - Utilizado para gerar texto de maneira autÃ´noma e fluente em portuguÃªs.

> Ambos os geradores usam o mesmo modelo neste exemplo, mas podem ser trocados por versÃµes distintas.

### âš–ï¸ Modelo Ãrbitro

- **neuralmind/bert-base-portuguese-cased**
  - VersÃ£o do BERT treinada em portuguÃªs brasileiro.
  - Utilizado para comparar o prompt com cada resposta, avaliando **clareza**, **relevÃ¢ncia** e **coerÃªncia**.

## ğŸ“Š CritÃ©rios de AvaliaÃ§Ã£o do Ãrbitro

| CritÃ©rio     | DefiniÃ§Ã£o                                                              |
|--------------|-------------------------------------------------------------------------|
| Clareza      | A resposta estÃ¡ bem formulada e compreensÃ­vel?                          |
| RelevÃ¢ncia   | A resposta realmente responde ao prompt do usuÃ¡rio?                    |
| CoerÃªncia    | A resposta Ã© lÃ³gica e gramaticalmente correta?                         |

> A avaliaÃ§Ã£o Ã© feita atravÃ©s da **similaridade semÃ¢ntica** entre o prompt e cada resposta.

## ğŸ–¥ï¸ Requisitos de Hardware

- CPU: 2 vCPU  
- RAM: 16 GB  
- Armazenamento: suficiente para carregar 3 modelos pequenos

## ğŸŒ Tecnologias Utilizadas

- [Gradio](https://www.gradio.app/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
- [Hugging Face Spaces](https://huggingface.co/spaces)
- PyTorch

## ğŸš€ Executando Localmente

```bash
git clone https://huggingface.co/spaces/SlickSlick/Chatbot-cascata-fmu
cd Chatbot-cascata-fmu
pip install -r requirements.txt
python app.py
```

## ğŸ§ª Exemplos de Uso

**Prompt:** "Qual Ã© a capital do Brasil?"

- **Resposta 1:** "A capital do Brasil Ã© BrasÃ­lia."
- **Resposta 2:** "Rio de Janeiro Ã© uma cidade importante do Brasil."
- **Escolhida pelo Ãrbitro:** Resposta 1
- **Justificativa:** Resposta 1 Ã© mais clara, direta e responde exatamente Ã  pergunta.

## ğŸ“¬ Contato e Autoria

- **Projeto acadÃªmico desenvolvido por:** Gabriel dos Reis Rodrigues Dias  
- **Curso:** CiÃªncia da ComputaÃ§Ã£o  
- **Universidade:** Centro UniversitÃ¡rio das Faculdades Metropolitanas Unidas â€“ FMU  
- **Professor:** RenÃ¨ Teixeira
